{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kenlm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK0_G-FR8YDV"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ynop/py-ctc-decode\n",
        "!pip3 install transformers datasets torchaudio\n",
        "!pip3 install https://github.com/kpu/kenlm/archive/master.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hB63kuh8pqh"
      },
      "source": [
        "%cd py-ctc-decode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNJJN4Q4K4V7"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from datasets import load_dataset\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer\n",
        "\n",
        "test_dataset = load_dataset(\"common_voice\", \"id\", split=\"test[:2%]\")\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"indonesian-nlp/wav2vec2-large-xlsr-indonesian\")\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"indonesian-nlp/wav2vec2-large-xlsr-indonesian\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"indonesian-nlp/wav2vec2-large-xlsr-indonesian\")\n",
        "\n",
        "# Preprocessing the datasets.\n",
        "# We need to read the aduio files as arrays\n",
        "def speech_file_to_array_fn(batch):\n",
        "  speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
        "  resampler = torchaudio.transforms.Resample(sampling_rate, 16_000)\n",
        "  batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
        "  return batch\n",
        "\n",
        "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
        "inputs = processor(test_dataset[:10][\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "\n",
        "predicted_ids = torch.argmax(logits, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Jd1apuXExM"
      },
      "source": [
        "# use your own kenlm model\n",
        "%%capture\n",
        "!wget http://hetzner.depia.wiki/idwiki.arpa.gz\n",
        "!gunzip idwiki.arpa.gz"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93NBAauuMYSR"
      },
      "source": [
        "vocab_dict = tokenizer.get_vocab()\n",
        "sort_vocab = sorted((value, key) for (key,value) in vocab_dict.items())\n",
        "vocab = [x[1].replace(\"|\", \" \") if x[1] not in tokenizer.all_special_tokens else \"\" for x in sort_vocab]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDo97amq8ss3"
      },
      "source": [
        "import ctcdecode\n",
        "import numpy as np\n",
        "\n",
        "vocabulary = vocab\n",
        "alpha = 2.5 # LM Weight\n",
        "beta = 0.0 # LM Usage Reward\n",
        "word_lm_scorer = ctcdecode.WordKenLMScorer('idwiki.arpa', alpha, beta) # use your own kenlm model\n",
        "decoder = ctcdecode.BeamSearchDecoder(\n",
        "    vocabulary,\n",
        "    num_workers=2,\n",
        "    beam_width=128,\n",
        "    scorers=[word_lm_scorer],\n",
        "    cutoff_prob=np.log(0.000001),\n",
        "    cutoff_top_n=40\n",
        ")\n",
        "text = decoder.decode_batch(logits.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIACEkxm9VCj"
      },
      "source": [
        "def lm_postprocess(text):\n",
        "  # my kenlm is borked\n",
        "  return ' '.join([x if len(x) > 1 else \"\" for x in text.split()]).strip()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsTwlV_c-GsL"
      },
      "source": [
        "text = [lm_postprocess(x) for x in text]\n",
        "print(\"LM Prediction: \", text)\n",
        "print(\"Prediction:\", processor.batch_decode(predicted_ids))\n",
        "print(\"Reference: \", test_dataset[:10][\"sentence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74oEEVtSBxGm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}